{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FzWv5XnPO0hw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from math import sqrt\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Configuration():\n",
        "  dim_token_emb= 768\n",
        "  attention_probs_dropout_prob= 0.1\n",
        "  classifier_dropout= None\n",
        "  gradient_checkpointing= False\n",
        "  hidden_act= \"gelu\"\n",
        "  hidden_dropout_prob= 0.1\n",
        "  hidden_size= 768\n",
        "  initializer_range= 0.02\n",
        "  intermediate_size= 3072\n",
        "  layer_norm_eps= 1e-12\n",
        "  max_position_embeddings= 512\n",
        "  model_type= \"encoder\"\n",
        "  num_attention_heads= 12\n",
        "  num_hidden_layers= 12\n",
        "  pad_token_id= 0\n",
        "  position_embedding_type= \"absolute\"\n",
        "  type_vocab_size= 2\n",
        "  use_cache= True\n",
        "  vocab_size= 30522"
      ],
      "metadata": {
        "id": "8a6sMBb-O6v-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Configuration()"
      ],
      "metadata": {
        "id": "PWkxTUbjPbOI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.dim_token_emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9yS6K5kPbnb",
        "outputId": "ba9ac386-1ef3-46f0-c132-5fceb6f945e3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value):\n",
        "  dim_k = query.size(-1)\n",
        "  scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
        "  weights = F.softmax(scores, dim=-1)\n",
        "  return torch.bmm(weights, value)"
      ],
      "metadata": {
        "id": "-yDfQBNNPd7i"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 임베딩 차원의 크기 : embed_dim\n",
        "# head_dim : 이 어텐션 헤드에서 사용될 쿼리, 키, 밸류 차원을 나타냄\n",
        "# Linear(a, b) a: 입력 특성수 , b : 출력 특성 수 자동으로 W, b 초기화 해줌\n",
        "\n",
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embed_dim, head_dim):\n",
        "    super().__init__()\n",
        "    self.w_q = nn.Linear(embed_dim, head_dim)\n",
        "    self.w_k = nn.Linear(embed_dim, head_dim)\n",
        "    self.w_v = nn.Linear(embed_dim, head_dim)\n",
        "\n",
        "  def forward(self, hidden_state):\n",
        "    attn_outputs = scaled_dot_product_attention(\n",
        "        self.w_q(hidden_state), self.w_k(hidden_state), self.w_v(hidden_state))\n",
        "    return attn_outputs"
      ],
      "metadata": {
        "id": "aE777DpnQyjs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    embed_dim = config.hidden_size\n",
        "    num_heads = config.num_attention_heads\n",
        "    head_dim = embed_dim // num_heads\n",
        "    self.heads = nn.ModuleList(\n",
        "        [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n",
        "    )\n",
        "    self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "  def forward(self, hidden_state):\n",
        "    x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
        "    x = self.output_linear(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "BJ86WH65TGwv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "    self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "    self.gelu = nn.GELU()\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear_1(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.linear_2(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "zslanT2BVoUi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
        "    self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
        "    self.attention = MultiHeadAttention(config)\n",
        "    self.feed_forward = FeedForward(config)\n",
        "\n",
        "  def forward(self, x):\n",
        "    hidden_state = self.layer_norm_1(x)\n",
        "    x = x + self.attention(hidden_state)\n",
        "    x = x + self.feed_forward(self.layer_norm_2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "1UDj_adEWK2G"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = TransformerEncoderLayer(config)"
      ],
      "metadata": {
        "id": "nGE6n5BIZDX3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.token_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "    self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "    self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
        "    self.dropout = nn.Dropout()\n",
        "\n",
        "  def forward(self, input_ids):\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n",
        "    token_embeddings = self.token_embeddings(input_ids)\n",
        "    position_embeddings = self.position_embeddings(position_ids)\n",
        "    embeddings = token_embeddings + position_embeddings\n",
        "    embeddings = self.layer_norm(embeddings)\n",
        "    embeddings = self.dropout(embeddings)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "JvvZAUYhZHVW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.embeddings = Embeddings(config)\n",
        "    self.layers = nn.ModuleList([TransformerEncoderLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embeddings(x)\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "zIBsLaF3d3OS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TransformerEncoder(config)"
      ],
      "metadata": {
        "id": "gIAxZOtFekiJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bcdDPyN0em9E"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(device)\n",
        "x = torch.randint(2, (2, config.max_position_embeddings))"
      ],
      "metadata": {
        "id": "3cw3Acyvepns"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_out = encoder(x)"
      ],
      "metadata": {
        "id": "HuVJG7qWeuL4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_out.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxCPBI0hevw9",
        "outputId": "8cb00467-4eae-4269-a254-d8912c2981a6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hBAqt-7VeyNC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}